{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM for Facial Matching. #\n",
    "\n",
    "Doing Support Vector Machine (SVM) regression on a subset of Cropped Yale face data. Data consists \n",
    "of 39 subjects, each with 65 greyscale images taken under different lighting conditions, then cropped\n",
    "to 192 x 168 pixels.\n",
    "\n",
    "My program assumes all the face images are 192 x 168. There is an image of size 640 x 480 pixels in each folder. Modified my program to exclude this \"ambient\" image.\n",
    "\n",
    "You can download the data set here:\n",
    "http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html\n",
    "\n",
    "\n",
    "---\n",
    "Importing libraries and going into the */CroppedYale* directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "#change into the CroppedYale directory\n",
    "os.chdir('CroppedYale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading up the data files. See the code comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#listing all the subdirectories in CroppedYale\n",
    "subdir = os.listdir()\n",
    "\n",
    "filename = []\n",
    "image = []\n",
    "target_name = []\n",
    "\n",
    "#length of the array\n",
    "PJG = 192*168\n",
    "\n",
    "\n",
    "examples = glob.glob(subdir[0]+'/*.pgm')[19]\n",
    "examples\n",
    "\n",
    "k=0\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in subdir[0:9]:\n",
    "    f = plt.imread(glob.glob(i+'/*.pgm')[19])\n",
    "    plt.suptitle('example of faces from 9 different subjects')\n",
    "    plt.subplot(331 + k).set_title(i)\n",
    "    plt.imshow(f)\n",
    "    k+=1\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "#for each subdirectory\n",
    "for i in subdir:\n",
    "    #listing all the pgm filenames in each subdirectory\n",
    "    s = glob.glob(i +'/*.pgm')\n",
    "    #pick a filename in the list of filenames\n",
    "    for file in s:\n",
    "        #read an image using a filename\n",
    "        img = plt.imread(file)\n",
    "        #exclude the bloody \"ambient\" image. Only process the 192x168 images!\n",
    "        if np.shape(img)== (192,168):\n",
    "            #append the filename to a lsit of filenames. Seems we don't actually use them though\n",
    "            filename += [file]\n",
    "            #append the subdir name to a list of subdir names. This will be the training target\n",
    "            target_name += [i]\n",
    "            #append image to a list of images\n",
    "            image += [img]\n",
    "            #flatten image to 1D and append the flattened image to a data array.\n",
    "            #sklearn only uses data like that\n",
    "            if k == 0:\n",
    "                #create array during the first iteration\n",
    "                data = np.array( [img.flatten()] )\n",
    "                k =1\n",
    "            else:\n",
    "                #append flattened image to already created data array\n",
    "                data = np.append(data, [img.flatten()], axis =0)    \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(target_name), np.shape(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn's support vector machine library.\n",
    "\n",
    "*train_test_split* is a function that splits your data and targets into:\n",
    "- data and targets used for training\n",
    "- data and targets used for testing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data sets: \n",
    "- 25% of data used for training, as *train_data*\n",
    "- 25% of target_name for training as *train_target_name*\n",
    "- 75% of data used for testing, as *test_data*\n",
    "- 75% of target_name for testing as *test_target_name*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.75\n",
    "train_data, test_data, train_target_name, test_target_name = train_test_split(\n",
    "    data, target_name, test_size = test_size, shuffle =True)\n",
    "\n",
    "\n",
    "test_length = np.shape(test_data)[0]\n",
    "print(test_length)\n",
    "np.shape(train_data), np.shape(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a support vector machine called *mesin* and training it using the *train_data* and *train_target_name*.\n",
    "\n",
    "We use the linear SVM. Previously tried polynomial kernel and radial basis RBG kernel, but surprisingly linear was the best.\n",
    "\n",
    "- Polynomial -> 60% to 70% correct results, with 99% data set used for training, and 1 percent for testing.\n",
    "\n",
    "- Radial basis -> 0% correct results no matter how I tweaked. It also took much longer to train!\n",
    "\n",
    "- Linear -> 80% accuracy with only 25% of data sets used for training, and it gets better with more training data sets! 92% accuracy with 90% of data used for training.\n",
    "\n",
    "### Linear:\n",
    "\n",
    "mesin = svm.SVC(kernel = 'linear', C = 10)\n",
    "\n",
    "### Polynomial:\n",
    "mesin = svm.SVC(kernel = 'poly', C = 10)\n",
    "\n",
    "### Radial Basis:\n",
    "mesin = svm.SVC(kernel = 'rbf', gamma = 0.1, C = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesin = svm.SVC(kernel='linear')\n",
    "mesin.fit(train_data, train_target_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the *mesin*, try it out using the *test_data*. It will return a list of directory names *ramal* which the machine thinks each row of *test_data* belongs to.\n",
    "\n",
    "For example, *test_data[25]* matches to *yaleB24*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ramal = mesin.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the folder names predicted by the SVM vs correct answer. \n",
    "\n",
    "Calculate percentage of predicted == correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_count = 0\n",
    "for i in range(test_length): \n",
    "    if i%int(100) ==0:\n",
    "        print(ramal[i], test_target_name[i], ramal[i]==test_target_name[i])\n",
    "    if ramal[i]==test_target_name[i]:\n",
    "        true_count += 1\n",
    "\n",
    "print('Accuracy =',100*true_count/test_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the images, what folder the mesin predicted vs a representative of the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for i in range(test_length):\n",
    "    \n",
    "    if i%int(test_length/25) ==0:\n",
    "        \n",
    "        img_predict = plt.imread((glob.glob(ramal[i] + '/*.pgm'))[10])\n",
    "        \n",
    "        \n",
    "        fig = plt.figure()\n",
    "        \n",
    "        if ramal[i] == test_target_name[i]:\n",
    "            fig.suptitle(\"Match \"+ramal[i])\n",
    "        else:\n",
    "            fig.suptitle(\"False Match \"+ramal[i]+ \"  \" +test_target_name[i])\n",
    "            \n",
    "        \n",
    "        plt.subplot(121).set_title('predicted '+ ramal[i])\n",
    "        plt.imshow(img_predict)\n",
    "        \n",
    "        plt.subplot(122).set_title('actual target '+ test_target_name[i])\n",
    "        plt.imshow(test_data[i].reshape((192,168)))\n",
    "        s = test_target_name\n",
    "        \n",
    "        print(i)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(25/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
